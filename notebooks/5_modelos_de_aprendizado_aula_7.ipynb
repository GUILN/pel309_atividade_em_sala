{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 7 - Modelos de Aprendizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicar Redes Bayesianas no Dataset Police\n",
    "\n",
    "Será feito um classificador bayesiano para prever se uma parada resultará ou não em prisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"../data/police.csv\"\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etl.main import PoliceDatasetEtl\n",
    "\n",
    "police_dataset_etl = PoliceDatasetEtl(df.copy())\n",
    "featured_df = police_dataset_etl.clean_transform()\n",
    "search_type_df = police_dataset_etl.get_search_type_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Probabilístico - Rede Bayesiana\n",
    "\n",
    "* Objetivo: Prever se uma parada policial resultará em prisão ou não\n",
    "* Utilizar classificador `Bernoli Naive Bayes`, como a distribuição do `target`(ser preso ou não) segue uma distribuição binária (`Bernouli`)\n",
    "* Utilizar a proporção 70% - 30% (70% treino, 30% teste)\n",
    "* Utilizar validação cruzada `k-fold`\n",
    "\n",
    "#### Notas:\n",
    "* **Seleção de features:** Dado a possibilidade de reutilização de trabalhos prévios sob esse dataset, as features utilizadas serão as mesmas descobertas como sendo as que possuem melhor relação de `mutual information score` com o *target* `is_arrested`, conforme utilizado no [notebook da aula 4](./etl_aula_4.ipynb). Portanto:\n",
    "    * search_type - Foi a única feature deixada como `one-hot-encoding`\n",
    "    * search_conducted (foi removido uma vez que deixava a acurácia pior)\n",
    "    * violation_level (foi removido uma vez que não altera a acurácia)\n",
    "    * driver_race (foi removido uma vez que não altera a acurácia)\n",
    "* **ETL e Feature Engineering:**\n",
    "    * Está sendo utilizada a class `PoliceDatasetEtl`, desenvolvida durante as atividades anteriores. Essa classe contém métodos de limpeza, extração e engenharia da feature `violation_level` que quantifica a feature original `violation` em uma variável contínua.\n",
    "* **Comparação:** Como o modelo de árvore de decisão já foi utilizado no [notebook da aula 4](./etl_aula_4.ipynb), faremos uma comparação do desempenho utilizando o modelo bayesiano para a distribuição de Bernouli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecionando e adequando as features\n",
    "\n",
    "Algumas features, incluindo o `target` deverão ser discretizados uma vez que são representadas por meio de variáveis categóricas. Para isso utilizaremos a técnica de `one hot encoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please, note search type is already transformed with \"one-hot-encoding\" in search_type_df dataset\n",
    "selected_features = [\n",
    "    # \"violation_level\",\n",
    "    # \"driver_race\",\n",
    "]\n",
    "target = \"is_arrested\"\n",
    "\n",
    "training_df = featured_df[target].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando `one-hot-encoder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo o encoding das features categóricas\n",
    "encoded_training_df = training_df.copy()\n",
    "category_feature_to_encode = [\n",
    "    # \"driver_race\",\n",
    "]\n",
    "\n",
    "# Fazendo o encoding da target\n",
    "y_encoded = y.copy()\n",
    "y_encoded = y_encoded.astype(\"category\")\n",
    "y_encoded = y_encoded.cat.codes\n",
    "\n",
    "for category in category_feature_to_encode:\n",
    "    encoded_training_df[category] = encoded_training_df[category].astype(\"category\")\n",
    "    encoded_training_df[f\"{category}_encoded\"] = encoded_training_df[category].cat.codes\n",
    "\n",
    "# encoded_training_df.pop(\"driver_race\")\n",
    "\n",
    "# merge training_df with search_type_df\n",
    "encoded_training_df = search_type_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo o split do dataset para treino - teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split training dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    encoded_training_df, y_encoded, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando e medindo a acurácia da `Rede Bayesiana`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 96.87 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Inicializando o classificador Naive Bayes\n",
    "naive_bayes_classifier = BernoulliNB()\n",
    "\n",
    "# Treinando o classificador Naive Bayes com os dados de treino\n",
    "naive_bayes_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo predições com o classificador Naive Bayes\n",
    "y_pred_test = naive_bayes_classifier.predict(X_test)\n",
    "\n",
    "# Medindo a acurácia do classificador Naive Bayes com os dados de teste\n",
    "acuracia = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Acurácia: {(acuracia * 100):.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando validação cruzada: `K-fold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.97119277 0.97127063 0.9687792  0.97033403 0.96854318]\n",
      "Fold 1:\n",
      "  - Índices dos exemplos de treinamento: [    0     1     2 ... 64215 64216 64217]\n",
      "Fold 2:\n",
      "  - Índices dos exemplos de treinamento: [    2     4     5 ... 64215 64216 64217]\n",
      "Fold 3:\n",
      "  - Índices dos exemplos de treinamento: [    0     1     2 ... 64212 64213 64214]\n",
      "Fold 4:\n",
      "  - Índices dos exemplos de treinamento: [    0     1     2 ... 64215 64216 64217]\n",
      "Fold 5:\n",
      "  - Índices dos exemplos de treinamento: [    0     1     3 ... 64215 64216 64217]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "training_df = search_type_df.copy()\n",
    "\n",
    "# Realizando o encoding do target\n",
    "y = featured_df.is_arrested\n",
    "y_encoded = y.copy()\n",
    "y_encoded = y_encoded.astype(\"category\")\n",
    "y_encoded = y_encoded.cat.codes\n",
    "\n",
    "# split training dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    encoded_training_df, y_encoded, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Inicializando o classificador Naive Bayes\n",
    "naive_bayes_classifier = BernoulliNB()\n",
    "\n",
    "# Inicializar o KFold para obter os índices de cada fold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Realizar validação cruzada com 5 folds no conjunto de treinamento\n",
    "scores = cross_val_score(naive_bayes_classifier, X_train, y_train, cv=kf)\n",
    "\n",
    "# Imprimir as pontuações de cada fold na validação cruzada\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "\n",
    "# Loop sobre os folds para obter os índices dos dados\n",
    "for fold, (train_index, _) in enumerate(kf.split(X_train)):\n",
    "    print(f\"Fold {fold + 1}:\")\n",
    "    print(f\"  - Índices dos exemplos de treinamento: {train_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusões\n",
    "\n",
    "* Das 4 features que pretendíamos utilizar, somente 1 (processada com `one-hot-encoding`) está sendo usada uma vez que removendo as outras features do modelo não alterava a acurácia, ou alterava positivamente.\n",
    "* Utilizando o crossvalidation com o `K-fold`, podemos constatar que a acurácia com o modelo treinado em cada fold é similar, ou apresenta baixa variação. Esse fato aumenta a confiança de que o modelo irá ter performance similar em produção uma vez que a distribuição dos dados das features consideradas para o propósito é consistente em cada fold.\n",
    "* Se comparado com o modelo de árvores de decisão implementado no [notebook da aula 4](./etl_aula_4.ipynb), podemos perceber uma acurácia muito similar, com baixa variação."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
